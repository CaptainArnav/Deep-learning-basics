{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "differential-religious",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing\n",
    "(train_data, train_target), (test_data, test_target) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "broke-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "emerging-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "def build_model() :\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1], )))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "respective-iceland",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "n = len(train_data) // k\n",
    "epochs = 100\n",
    "all_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "controlling-improvement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold: 0\n",
      "processing fold: 1\n",
      "processing fold: 2\n",
      "processing fold: 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i in range(k) :\n",
    "    print('processing fold:', i)\n",
    "    val_data = train_data[n * i : n * (i + 1)]\n",
    "    val_target = train_target[n * i : n * (i + 1)]\n",
    "    \n",
    "    partial_train_data = np.concatenate([train_data[:n * i],train_data[n * (i + 1):]], axis=0)\n",
    "    partial_train_target = np.concatenate([train_target[:n * i],train_target[n * (i + 1):]], axis=0)\n",
    "    \n",
    "    model = build_model()\n",
    "    model.fit(partial_train_data, partial_train_target, epochs=epochs, batch_size=1, verbose=0)\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_target, verbose=0)\n",
    "    all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aboriginal-compromise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.135653018951416, 3.0914225578308105, 2.5584053993225098, 2.213132858276367]\n",
      "2.499653458595276\n"
     ]
    }
   ],
   "source": [
    "print(all_scores)\n",
    "print(np.mean(all_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "serious-disease",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 644us/step - loss: 16.1261 - mae: 2.4609\n"
     ]
    }
   ],
   "source": [
    "test_mse, test_mae = model.evaluate(test_data, test_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
